{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74495da4-0af4-4acb-9cba-a33af106502e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e93e685e-abdf-4dd3-9bcb-506bb76829b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "963c48dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table if exists student\")\n",
    "spark.sql(\"drop table if exists existing_students\")\n",
    "spark.sql(\"drop table if exists students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f991e",
   "metadata": {},
   "source": [
    "# How to create a Delta Table with Change Data Feed enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "226657d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE students (id LONG, name STRING, age LONG)\n",
    "USING delta \n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef3d44",
   "metadata": {},
   "source": [
    "# How to enable Change Data Feed on an existing Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77994aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE existing_students (id LONG, name STRING, age LONG)\n",
    "USING delta\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aff349fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "ALTER TABLE existing_students SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7abf2",
   "metadata": {},
   "source": [
    "# How to read a Delta Lake Change Data Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8abd8f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First change, append some data\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO students VALUES (0,\"Matt\", 20), (1, \"Jim\", 25), (2, \"Nick\", 30)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a93e5fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second change, delete some data\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM students WHERE id = 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f9c4ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third change, delete some data\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE students SET age = 30 WHERE id = 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb99211",
   "metadata": {},
   "source": [
    "## Read Change Data Feed in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ed977dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------------+---------------+--------------------+\n",
      "| id|name|age|_change_type|_commit_version|   _commit_timestamp|\n",
      "+---+----+---+------------+---------------+--------------------+\n",
      "|  0|Matt| 20|      insert|              1|2023-04-19 11:28:...|\n",
      "|  2|Nick| 30|      insert|              1|2023-04-19 11:28:...|\n",
      "|  1| Jim| 25|      insert|              1|2023-04-19 11:28:...|\n",
      "+---+----+---+------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes('students', 0, 1)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fee6514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------------+---------------+--------------------+\n",
      "| id|name|age|_change_type|_commit_version|   _commit_timestamp|\n",
      "+---+----+---+------------+---------------+--------------------+\n",
      "|  2|Nick| 30|      delete|              2|2023-04-19 11:28:...|\n",
      "+---+----+---+------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes('students', 2, 2)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "025a070a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----------------+---------------+--------------------+\n",
      "| id|name|age|    _change_type|_commit_version|   _commit_timestamp|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "|  1| Jim| 25| update_preimage|              3|2023-04-19 11:28:...|\n",
      "|  1| Jim| 30|update_postimage|              3|2023-04-19 11:28:...|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes('students', 3, 3)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3c7c5a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----------------+---------------+--------------------+\n",
      "| id|name|age|    _change_type|_commit_version|   _commit_timestamp|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "|  1| Jim| 25| update_preimage|              3|2023-04-19 11:28:...|\n",
      "|  1| Jim| 30|update_postimage|              3|2023-04-19 11:28:...|\n",
      "|  2|Nick| 30|          delete|              2|2023-04-19 11:28:...|\n",
      "|  0|Matt| 20|          insert|              1|2023-04-19 11:28:...|\n",
      "|  2|Nick| 30|          insert|              1|2023-04-19 11:28:...|\n",
      "|  1| Jim| 25|          insert|              1|2023-04-19 11:28:...|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes('students', 0)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "778a4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use table_changes_by_path to read using a path instead of a table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c6897fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the students table for example purposes\n",
    "path = spark.sql(\"DESCRIBE EXTENDED STUDENTS\") \\\n",
    "     .where(\"col_name = 'Location'\") \\\n",
    "     .collect()[0].data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9cd2ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------------+---------------+--------------------+\n",
      "| id| name|age|    _change_type|_commit_version|   _commit_timestamp|\n",
      "+---+-----+---+----------------+---------------+--------------------+\n",
      "|  1|  Jim| 25| update_preimage|              2|2023-04-19 09:01:...|\n",
      "|  1|  Jim| 30|update_postimage|              2|2023-04-19 09:01:...|\n",
      "|  2| Nick| 30|          delete|              2|2023-04-19 09:01:...|\n",
      "|  3|Denny| 35|          insert|              2|2023-04-19 09:01:...|\n",
      "|  0| Matt| 20|          insert|              1|2023-04-19 09:01:...|\n",
      "|  2| Nick| 30|          insert|              1|2023-04-19 09:01:...|\n",
      "|  1|  Jim| 25|          insert|              1|2023-04-19 09:01:...|\n",
      "+---+-----+---+----------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes_by_path('{}', 0)\n",
    "\"\"\".format(path)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5201c51",
   "metadata": {},
   "source": [
    "## Read Change Data Feed as a stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf20421f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, age: bigint, _change_type: string, _commit_version: bigint, _commit_timestamp: timestamp]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting version only\n",
    "spark.readStream.format(\"delta\") \\\n",
    "  .option(\"readChangeFeed\", \"true\") \\\n",
    "  .option(\"startingVersion\", 0) \\\n",
    "  .table(\"students\")\n",
    "\n",
    "# Starting timestamp and path based\n",
    "spark.readStream.format(\"delta\") \\\n",
    "  .option(\"readChangeFeed\", \"true\") \\\n",
    "  .option(\"startingTimestamp\", \"2023-04-19 05:35:43\") \\\n",
    "  .load(path)\n",
    "\n",
    "# Starting from the latest snapshot (no version or timestamp provided)\n",
    "spark.readStream.format(\"delta\") \\\n",
    "  .option(\"readChangeFeed\", \"true\") \\\n",
    "  .table(\"students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14296fd3",
   "metadata": {},
   "source": [
    "# How to apply change data downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "00038437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----------------+---------------+--------------------+\n",
      "| id|name|age|    _change_type|_commit_version|   _commit_timestamp|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "|  1| Jim| 25| update_preimage|              3|2023-04-19 11:28:...|\n",
      "|  1| Jim| 30|update_postimage|              3|2023-04-19 11:28:...|\n",
      "|  2|Nick| 30|          delete|              2|2023-04-19 11:28:...|\n",
      "|  0|Matt| 20|          insert|              1|2023-04-19 11:28:...|\n",
      "|  2|Nick| 30|          insert|              1|2023-04-19 11:28:...|\n",
      "|  1| Jim| 25|          insert|              1|2023-04-19 11:28:...|\n",
      "+---+----+---+----------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM table_changes_by_path('{}', 0)\n",
    "\"\"\".format(path)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce6344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf05cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b28156e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW changes AS\n",
    "    SELECT cast(col1 as LONG) as id, \n",
    "           col2 as name, \n",
    "           cast(col3 as LONG) as age,\n",
    "           col4 as change_type \n",
    "    FROM VALUES (3,\"Denny\", 35, \"INSERT\"), (2, \"Nick\", 30, \"DELETE\"), (1, \"Jim\", 30, \"UPDATE\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ff69f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/19 09:01:08 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n",
      "23/04/19 09:01:08 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n",
      "23/04/19 09:01:08 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                3|               1|               1|                1|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "MERGE INTO students t\n",
    "USING changes s\n",
    "ON t.id = s.id\n",
    "WHEN MATCHED AND s.change_type = \"UPDATE\" \n",
    "    THEN UPDATE SET name = s.name, age = s.age\n",
    "WHEN MATCHED AND s.change_type = \"DELETE\"\n",
    "    THEN DELETE\n",
    "WHEN NOT MATCHED AND s.change_type = \"INSERT\"\n",
    "    THEN INSERT (id, name, age) VALUES (s.id, s.name, s.age)\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958c100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark-332-delta-230] *",
   "language": "python",
   "name": "conda-env-pyspark-332-delta-230-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
